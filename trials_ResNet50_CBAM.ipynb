{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_ResNet50(trainable_extractor = False):\n",
    "    \"\"\"\n",
    "    Create an ResNet50 model.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): ResNet50 model.\n",
    "    \"\"\"\n",
    "    weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "    model = torchvision.models.resnet50(weights=weights).to(device)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = trainable_extractor\n",
    "    \n",
    "    model.fc= nn.Sequential(\n",
    "    torch.nn.Linear(2048,1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1000,500),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(in_features=500,\n",
    "                    out_features=2,\n",
    "                    bias=True)\n",
    "    ).to(device)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    # Recreate the classifier layer and seed it to the target device\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "ResNet (ResNet)                          [1, 3, 224, 224]          [1, 2]                    --                        --                        --\n",
       "├─Conv2d (conv1)                         [1, 3, 224, 224]          [1, 64, 112, 112]         (9,408)                   [7, 7]                    118,013,952\n",
       "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]         [1, 64, 112, 112]         (128)                     --                        128\n",
       "├─ReLU (relu)                            [1, 64, 112, 112]         [1, 64, 112, 112]         --                        --                        --\n",
       "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]         [1, 64, 56, 56]           --                        3                         --\n",
       "├─Sequential (layer1)                    [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Bottleneck (0)                    [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           (4,096)                   [1, 1]                    12,845,056\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           (36,864)                  [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]           [1, 256, 56, 56]          (16,384)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]          [1, 256, 56, 56]          (512)                     --                        512\n",
       "│    │    └─Sequential (downsample)      [1, 64, 56, 56]           [1, 256, 56, 56]          (16,896)                  --                        51,380,736\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Bottleneck (1)                    [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]          [1, 64, 56, 56]           (16,384)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           (36,864)                  [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]           [1, 256, 56, 56]          (16,384)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]          [1, 256, 56, 56]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Bottleneck (2)                    [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]          [1, 64, 56, 56]           (16,384)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           (36,864)                  [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           (128)                     --                        128\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]           [1, 256, 56, 56]          (16,384)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]          [1, 256, 56, 56]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "├─Sequential (layer2)                    [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Bottleneck (0)                    [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]          [1, 128, 56, 56]          (32,768)                  [1, 1]                    102,760,448\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 56, 56]          [1, 128, 56, 56]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 56, 56]          [1, 128, 56, 56]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 56, 56]          [1, 128, 28, 28]          (147,456)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]          [1, 512, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]          [1, 512, 28, 28]          (1,024)                   --                        1,024\n",
       "│    │    └─Sequential (downsample)      [1, 256, 56, 56]          [1, 512, 28, 28]          (132,096)                 --                        102,761,472\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Bottleneck (1)                    [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]          [1, 128, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          (147,456)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]          [1, 512, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]          [1, 512, 28, 28]          (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Bottleneck (2)                    [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]          [1, 128, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          (147,456)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]          [1, 512, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]          [1, 512, 28, 28]          (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Bottleneck (3)                    [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]          [1, 128, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          (147,456)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          (256)                     --                        256\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]          [1, 512, 28, 28]          (65,536)                  [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]          [1, 512, 28, 28]          (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "├─Sequential (layer3)                    [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (0)                    [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]          [1, 256, 28, 28]          (131,072)                 [1, 1]                    102,760,448\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 28, 28]          [1, 256, 28, 28]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 28, 28]          [1, 256, 28, 28]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 28, 28]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─Sequential (downsample)      [1, 512, 28, 28]          [1, 1024, 14, 14]         (526,336)                 --                        102,762,496\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (1)                    [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 256, 14, 14]          (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (2)                    [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 256, 14, 14]          (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (3)                    [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 256, 14, 14]          (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (4)                    [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 256, 14, 14]          (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    └─Bottleneck (5)                    [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 256, 14, 14]          (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          (589,824)                 [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          (512)                     --                        512\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]          [1, 1024, 14, 14]         (262,144)                 [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]         [1, 1024, 14, 14]         (2,048)                   --                        2,048\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --                        --\n",
       "├─Sequential (layer4)                    [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --                        --\n",
       "│    └─Bottleneck (0)                    [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]         [1, 512, 14, 14]          (524,288)                 [1, 1]                    102,760,448\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 14, 14]          [1, 512, 14, 14]          (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 14, 14]          [1, 512, 7, 7]            (2,359,296)               [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]            [1, 2048, 7, 7]           (1,048,576)               [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]           [1, 2048, 7, 7]           (4,096)                   --                        4,096\n",
       "│    │    └─Sequential (downsample)      [1, 1024, 14, 14]         [1, 2048, 7, 7]           (2,101,248)               --                        102,764,544\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --                        --\n",
       "│    └─Bottleneck (1)                    [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7]           [1, 512, 7, 7]            (1,048,576)               [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            (2,359,296)               [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]            [1, 2048, 7, 7]           (1,048,576)               [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]           [1, 2048, 7, 7]           (4,096)                   --                        4,096\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --                        --\n",
       "│    └─Bottleneck (2)                    [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --                        --\n",
       "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7]           [1, 512, 7, 7]            (1,048,576)               [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            (2,359,296)               [3, 3]                    115,605,504\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            (1,024)                   --                        1,024\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]            [1, 2048, 7, 7]           (1,048,576)               [1, 1]                    51,380,224\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]           [1, 2048, 7, 7]           (4,096)                   --                        4,096\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --                        --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [1, 2048, 7, 7]           [1, 2048, 1, 1]           --                        --                        --\n",
       "├─Sequential (fc)                        [1, 2048]                 [1, 2]                    --                        --                        --\n",
       "│    └─Linear (0)                        [1, 2048]                 [1, 1000]                 2,049,000                 --                        2,049,000\n",
       "│    └─ReLU (1)                          [1, 1000]                 [1, 1000]                 --                        --                        --\n",
       "│    └─Linear (2)                        [1, 1000]                 [1, 500]                  500,500                   --                        500,500\n",
       "│    └─Dropout (3)                       [1, 500]                  [1, 500]                  --                        --                        --\n",
       "│    └─Linear (4)                        [1, 500]                  [1, 2]                    1,002                     --                        1,002\n",
       "=====================================================================================================================================================================\n",
       "Total params: 26,058,534\n",
       "Trainable params: 2,550,502\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (G): 4.09\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 177.84\n",
       "Params size (MB): 104.23\n",
       "Estimated Total Size (MB): 282.67\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orinin = init_model_ResNet50()\n",
    "summary(model_orinin, input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"], depth=3, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_orinin.layer1, col_names=[\"num_params\", \"kernel_size\"], depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Channel_Attention                        --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Flatten: 2-1                      --\n",
       "│    └─Linear: 2-2                       260\n",
       "│    └─ReLU: 2-3                         --\n",
       "│    └─Linear: 2-4                       320\n",
       "=================================================================\n",
       "Total params: 580\n",
       "Trainable params: 580\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Channel_Attention(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ChannelAttention                         --\n",
       "├─AdaptiveAvgPool2d: 1-1                 --\n",
       "├─AdaptiveMaxPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Conv2d: 2-1                       256\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Conv2d: 2-3                       256\n",
       "├─Sigmoid: 1-4                           --\n",
       "=================================================================\n",
       "Total params: 512\n",
       "Trainable params: 512\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ChannelAttention(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# khoi tao model ResNet50 CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.channel_attention(x) * x\n",
    "        out = self.spatial_attention(out) * out\n",
    "        return out\n",
    "\n",
    "class BottleneckWithCBAM(torchvision.models.resnet.Bottleneck):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BottleneckWithCBAM, self).__init__(inplanes, planes, stride, downsample)\n",
    "        self.cbam = CBAM(planes * self.expansion)\n",
    "        self.planes = planes\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.cbam(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def init_model_ResNet50_CBAM(trainable_extractor = False, device='cuda'):\n",
    "    \"\"\"\n",
    "    Create an ResNet50 model with CBAM attention.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): ResNet50 model with CBAM.\n",
    "    \"\"\"\n",
    "    weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "    model = torchvision.models.resnet50(weights=weights).to(device)\n",
    "\n",
    "    for name, module in model.named_children():\n",
    "        if name not in ['conv1', 'bn1', 'relu', 'maxpool', 'fc']:\n",
    "            for block_name, block in module.named_children():\n",
    "                if isinstance(block, torchvision.models.resnet.Bottleneck):\n",
    "                    inplanes = block.conv1.in_channels\n",
    "                    planes = block.conv2.out_channels # Thử lấy planes từ conv2\n",
    "                    stride = block.conv2.stride[0]\n",
    "                    downsample = block.downsample\n",
    "                    setattr(module, block_name, BottleneckWithCBAM(inplanes, planes, stride, downsample))\n",
    "\n",
    "    # Freeze layers (tương tự như hàm gốc)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = trainable_extractor\n",
    "\n",
    "    # Thay thế lớp fully connected\n",
    "    model.fc= nn.Sequential(\n",
    "        torch.nn.Linear(2048,1024),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(1024,512),\n",
    "        torch.nn.Dropout(),\n",
    "        torch.nn.Linear(in_features=512,\n",
    "                        out_features=2,\n",
    "                        bias=True)\n",
    "    )\n",
    "    # Chuyển toàn bộ model lên device sau khi đã thực hiện các thay đổi\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    # model.fc = model.fc.to(device) # Đảm bảo cả lớp fc cũng được chuyển\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layer1.0.cbam.channel_attention.fc.0.weight', 'layer1.0.cbam.channel_attention.fc.2.weight', 'layer1.0.cbam.spatial_attention.conv.weight', 'layer1.1.cbam.channel_attention.fc.0.weight', 'layer1.1.cbam.channel_attention.fc.2.weight', 'layer1.1.cbam.spatial_attention.conv.weight', 'layer1.2.cbam.channel_attention.fc.0.weight', 'layer1.2.cbam.channel_attention.fc.2.weight', 'layer1.2.cbam.spatial_attention.conv.weight', 'layer2.0.cbam.channel_attention.fc.0.weight', 'layer2.0.cbam.channel_attention.fc.2.weight', 'layer2.0.cbam.spatial_attention.conv.weight', 'layer2.1.cbam.channel_attention.fc.0.weight', 'layer2.1.cbam.channel_attention.fc.2.weight', 'layer2.1.cbam.spatial_attention.conv.weight', 'layer2.2.cbam.channel_attention.fc.0.weight', 'layer2.2.cbam.channel_attention.fc.2.weight', 'layer2.2.cbam.spatial_attention.conv.weight', 'layer2.3.cbam.channel_attention.fc.0.weight', 'layer2.3.cbam.channel_attention.fc.2.weight', 'layer2.3.cbam.spatial_attention.conv.weight', 'layer3.0.cbam.channel_attention.fc.0.weight', 'layer3.0.cbam.channel_attention.fc.2.weight', 'layer3.0.cbam.spatial_attention.conv.weight', 'layer3.1.cbam.channel_attention.fc.0.weight', 'layer3.1.cbam.channel_attention.fc.2.weight', 'layer3.1.cbam.spatial_attention.conv.weight', 'layer3.2.cbam.channel_attention.fc.0.weight', 'layer3.2.cbam.channel_attention.fc.2.weight', 'layer3.2.cbam.spatial_attention.conv.weight', 'layer3.3.cbam.channel_attention.fc.0.weight', 'layer3.3.cbam.channel_attention.fc.2.weight', 'layer3.3.cbam.spatial_attention.conv.weight', 'layer3.4.cbam.channel_attention.fc.0.weight', 'layer3.4.cbam.channel_attention.fc.2.weight', 'layer3.4.cbam.spatial_attention.conv.weight', 'layer3.5.cbam.channel_attention.fc.0.weight', 'layer3.5.cbam.channel_attention.fc.2.weight', 'layer3.5.cbam.spatial_attention.conv.weight', 'layer4.0.cbam.channel_attention.fc.0.weight', 'layer4.0.cbam.channel_attention.fc.2.weight', 'layer4.0.cbam.spatial_attention.conv.weight', 'layer4.1.cbam.channel_attention.fc.0.weight', 'layer4.1.cbam.channel_attention.fc.2.weight', 'layer4.1.cbam.spatial_attention.conv.weight', 'layer4.2.cbam.channel_attention.fc.0.weight', 'layer4.2.cbam.channel_attention.fc.2.weight', 'layer4.2.cbam.spatial_attention.conv.weight', 'fc.0.weight', 'fc.0.bias', 'fc.2.weight', 'fc.2.bias', 'fc.4.weight', 'fc.4.bias'], unexpected_keys=['fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_model_ResNet50_CBAM(True)\n",
    "weight = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model.load_state_dict(weight.get_state_dict(progress=True), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name in weight.get_state_dict():\n",
    "        param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds                 Trainable\n",
       "==================================================================================================================================================================================================================\n",
       "ResNet (ResNet)                                              [16, 3, 224, 224]         [16, 2]                   --                        --                        --                        Partial\n",
       "├─Conv2d (conv1)                                             [16, 3, 224, 224]         [16, 64, 112, 112]        (9,408)                   [7, 7]                    1,888,223,232             False\n",
       "├─BatchNorm2d (bn1)                                          [16, 64, 112, 112]        [16, 64, 112, 112]        (128)                     --                        2,048                     False\n",
       "├─ReLU (relu)                                                [16, 64, 112, 112]        [16, 64, 112, 112]        --                        --                        --                        --\n",
       "├─MaxPool2d (maxpool)                                        [16, 64, 112, 112]        [16, 64, 56, 56]          --                        3                         --                        --\n",
       "├─Sequential (layer1)                                        [16, 64, 56, 56]          [16, 256, 56, 56]         --                        --                        --                        Partial\n",
       "│    └─BottleneckWithCBAM (0)                                [16, 64, 56, 56]          [16, 256, 56, 56]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          (4,096)                   [1, 1]                    205,520,896               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          (36,864)                  [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         (512)                     --                        8,192                     False\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           8,192                     --                        131,072                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           (recursive)               --                        131,072                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 256, 1, 1]           [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 256, 56, 56]         [16, 1, 56, 56]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 56, 56]           [16, 1, 56, 56]           98                        [7, 7]                    4,917,248                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 56, 56]           [16, 1, 56, 56]           --                        --                        --                        --\n",
       "│    │    └─Sequential (downsample)                          [16, 64, 56, 56]          [16, 256, 56, 56]         --                        --                        --                        False\n",
       "│    │    │    └─Conv2d (0)                                  [16, 64, 56, 56]          [16, 256, 56, 56]         (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 256, 56, 56]         [16, 256, 56, 56]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (1)                                [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 64, 56, 56]          (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          (36,864)                  [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         (512)                     --                        8,192                     False\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           8,192                     --                        131,072                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           (recursive)               --                        131,072                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 256, 1, 1]           [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 256, 56, 56]         [16, 1, 56, 56]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 56, 56]           [16, 1, 56, 56]           98                        [7, 7]                    4,917,248                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 56, 56]           [16, 1, 56, 56]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (2)                                [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 64, 56, 56]          (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          (36,864)                  [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          (128)                     --                        2,048                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         (16,384)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         (512)                     --                        8,192                     False\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           8,192                     --                        131,072                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 256, 56, 56]         [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 256, 1, 1]           [16, 256, 1, 1]           (recursive)               --                        131,072                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 256, 1, 1]           [16, 256, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 256, 56, 56]         [16, 1, 56, 56]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 56, 56]           [16, 1, 56, 56]           98                        [7, 7]                    4,917,248                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 56, 56]           [16, 1, 56, 56]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --                        --                        --\n",
       "├─Sequential (layer2)                                        [16, 256, 56, 56]         [16, 512, 28, 28]         --                        --                        --                        Partial\n",
       "│    └─BottleneckWithCBAM (0)                                [16, 256, 56, 56]         [16, 512, 28, 28]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 128, 56, 56]         (32,768)                  [1, 1]                    1,644,167,168             False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 56, 56]         [16, 128, 56, 56]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 56, 56]         [16, 128, 56, 56]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 56, 56]         [16, 128, 28, 28]         (147,456)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           32,768                    --                        524,288                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           (recursive)               --                        524,288                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 512, 1, 1]           [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 512, 28, 28]         [16, 1, 28, 28]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 28, 28]           [16, 1, 28, 28]           98                        [7, 7]                    1,229,312                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 28, 28]           [16, 1, 28, 28]           --                        --                        --                        --\n",
       "│    │    └─Sequential (downsample)                          [16, 256, 56, 56]         [16, 512, 28, 28]         --                        --                        --                        False\n",
       "│    │    │    └─Conv2d (0)                                  [16, 256, 56, 56]         [16, 512, 28, 28]         (131,072)                 [1, 1]                    1,644,167,168             False\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 512, 28, 28]         [16, 512, 28, 28]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (1)                                [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 128, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         (147,456)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           32,768                    --                        524,288                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           (recursive)               --                        524,288                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 512, 1, 1]           [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 512, 28, 28]         [16, 1, 28, 28]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 28, 28]           [16, 1, 28, 28]           98                        [7, 7]                    1,229,312                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 28, 28]           [16, 1, 28, 28]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (2)                                [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 128, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         (147,456)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           32,768                    --                        524,288                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           (recursive)               --                        524,288                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 512, 1, 1]           [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 512, 28, 28]         [16, 1, 28, 28]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 28, 28]           [16, 1, 28, 28]           98                        [7, 7]                    1,229,312                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 28, 28]           [16, 1, 28, 28]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 128, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         (147,456)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         (256)                     --                        4,096                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         (65,536)                  [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           32,768                    --                        524,288                   True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 512, 28, 28]         [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 512, 1, 1]           [16, 512, 1, 1]           (recursive)               --                        524,288                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 512, 1, 1]           [16, 512, 1, 1]           --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 512, 28, 28]         [16, 1, 28, 28]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 28, 28]           [16, 1, 28, 28]           98                        [7, 7]                    1,229,312                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 28, 28]           [16, 1, 28, 28]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --                        --                        --\n",
       "├─Sequential (layer3)                                        [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    └─BottleneckWithCBAM (0)                                [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 256, 28, 28]         (131,072)                 [1, 1]                    1,644,167,168             False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 28, 28]         [16, 256, 28, 28]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 28, 28]         [16, 256, 28, 28]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 28, 28]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─Sequential (downsample)                          [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        --                        --                        False\n",
       "│    │    │    └─Conv2d (0)                                  [16, 512, 28, 28]         [16, 1024, 14, 14]        (524,288)                 [1, 1]                    1,644,167,168             False\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (1)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (2)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (4)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (5)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         (589,824)                 [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         (512)                     --                        8,192                     False\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        (262,144)                 [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        (2,048)                   --                        32,768                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          131,072                   --                        2,097,152                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 1024, 14, 14]        [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 1024, 1, 1]          [16, 1024, 1, 1]          (recursive)               --                        2,097,152                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1024, 1, 1]          [16, 1024, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 1024, 14, 14]        [16, 1, 14, 14]           --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 14, 14]           [16, 1, 14, 14]           98                        [7, 7]                    307,328                   True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 14, 14]           [16, 1, 14, 14]           --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --                        --                        --\n",
       "├─Sequential (layer4)                                        [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        --                        --                        Partial\n",
       "│    └─BottleneckWithCBAM (0)                                [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 512, 14, 14]         (524,288)                 [1, 1]                    1,644,167,168             False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 512, 14, 14]         [16, 512, 14, 14]         (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 14, 14]         [16, 512, 14, 14]         --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 512, 14, 14]         [16, 512, 7, 7]           (2,359,296)               [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 512, 7, 7]           [16, 512, 7, 7]           (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 512, 7, 7]           [16, 2048, 7, 7]          (1,048,576)               [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          (4,096)                   --                        65,536                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          524,288                   --                        8,388,608                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          (recursive)               --                        8,388,608                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 2048, 1, 1]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 2048, 7, 7]          [16, 1, 7, 7]             --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 7, 7]             [16, 1, 7, 7]             98                        [7, 7]                    76,832                    True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 7, 7]             [16, 1, 7, 7]             --                        --                        --                        --\n",
       "│    │    └─Sequential (downsample)                          [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        --                        --                        False\n",
       "│    │    │    └─Conv2d (0)                                  [16, 1024, 14, 14]        [16, 2048, 7, 7]          (2,097,152)               [1, 1]                    1,644,167,168             False\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 2048, 7, 7]          [16, 2048, 7, 7]          (4,096)                   --                        65,536                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (1)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 2048, 7, 7]          [16, 512, 7, 7]           (1,048,576)               [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 512, 7, 7]           [16, 512, 7, 7]           (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 512, 7, 7]           [16, 512, 7, 7]           (2,359,296)               [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 512, 7, 7]           [16, 512, 7, 7]           (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 512, 7, 7]           [16, 2048, 7, 7]          (1,048,576)               [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          (4,096)                   --                        65,536                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          524,288                   --                        8,388,608                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          (recursive)               --                        8,388,608                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 2048, 1, 1]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 2048, 7, 7]          [16, 1, 7, 7]             --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 7, 7]             [16, 1, 7, 7]             98                        [7, 7]                    76,832                    True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 7, 7]             [16, 1, 7, 7]             --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        --\n",
       "│    └─BottleneckWithCBAM (2)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        Partial\n",
       "│    │    └─Conv2d (conv1)                                   [16, 2048, 7, 7]          [16, 512, 7, 7]           (1,048,576)               [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 512, 7, 7]           [16, 512, 7, 7]           (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 512, 7, 7]           [16, 512, 7, 7]           (2,359,296)               [3, 3]                    1,849,688,064             False\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 512, 7, 7]           [16, 512, 7, 7]           (1,024)                   --                        16,384                    False\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --                        --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 512, 7, 7]           [16, 2048, 7, 7]          (1,048,576)               [1, 1]                    822,083,584               False\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          (4,096)                   --                        65,536                    False\n",
       "│    │    └─CBAM (cbam)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        True\n",
       "│    │    │    └─ChannelAttention (channel_attention)        [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        True\n",
       "│    │    │    │    └─AdaptiveAvgPool2d (avg_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          524,288                   --                        8,388,608                 True\n",
       "│    │    │    │    └─AdaptiveMaxPool2d (max_pool)           [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    │    └─Sequential (fc)                        [16, 2048, 1, 1]          [16, 2048, 1, 1]          (recursive)               --                        8,388,608                 True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 2048, 1, 1]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "│    │    │    └─SpatialAttention (spatial_attention)        [16, 2048, 7, 7]          [16, 1, 7, 7]             --                        --                        --                        True\n",
       "│    │    │    │    └─Conv2d (conv)                          [16, 2, 7, 7]             [16, 1, 7, 7]             98                        [7, 7]                    76,832                    True\n",
       "│    │    │    │    └─Sigmoid (sigmoid)                      [16, 1, 7, 7]             [16, 1, 7, 7]             --                        --                        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --                        --                        --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --                        --                        --\n",
       "├─Sequential (fc)                                            [16, 2048]                [16, 2]                   --                        --                        --                        True\n",
       "│    └─Linear (0)                                            [16, 2048]                [16, 1024]                2,098,176                 --                        33,570,816                True\n",
       "│    └─ReLU (1)                                              [16, 1024]                [16, 1024]                --                        --                        --                        --\n",
       "│    └─Linear (2)                                            [16, 1024]                [16, 512]                 524,800                   --                        8,396,800                 True\n",
       "│    └─Dropout (3)                                           [16, 512]                 [16, 512]                 --                        --                        --                        --\n",
       "│    └─Linear (4)                                            [16, 512]                 [16, 2]                   1,026                     --                        16,416                    True\n",
       "==================================================================================================================================================================================================================\n",
       "Total params: 28,648,546\n",
       "Trainable params: 5,140,514\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (G): 65.54\n",
       "==================================================================================================================================================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2851.26\n",
       "Params size (MB): 114.59\n",
       "Estimated Total Size (MB): 2975.49\n",
       "=================================================================================================================================================================================================================="
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(16, 3, 224, 224), row_settings=[\"var_names\"], col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\", \"trainable\"], depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Param #                   Trainable\n",
       "===============================================================================================\n",
       "Sequential                                    --                        False\n",
       "├─BottleneckWithCBAM: 1-1                     --                        False\n",
       "│    └─Conv2d: 2-1                            (4,096)                   False\n",
       "│    └─BatchNorm2d: 2-2                       (128)                     False\n",
       "│    └─Conv2d: 2-3                            (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-4                       (128)                     False\n",
       "│    └─Conv2d: 2-5                            (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-6                       (512)                     False\n",
       "│    └─ReLU: 2-7                              --                        --\n",
       "│    └─Sequential: 2-8                        --                        False\n",
       "│    │    └─Conv2d: 3-1                       (16,384)                  False\n",
       "│    │    └─BatchNorm2d: 3-2                  (512)                     False\n",
       "│    └─CBAM: 2-9                              --                        False\n",
       "│    │    └─ChannelAttention: 3-3             --                        False\n",
       "│    │    │    └─AdaptiveAvgPool2d: 4-1       --                        --\n",
       "│    │    │    └─AdaptiveMaxPool2d: 4-2       --                        --\n",
       "│    │    │    └─Sequential: 4-3              --                        False\n",
       "│    │    │    │    └─Conv2d: 5-1             (4,096)                   False\n",
       "│    │    │    │    └─ReLU: 5-2               --                        --\n",
       "│    │    │    │    └─Conv2d: 5-3             (4,096)                   False\n",
       "│    │    │    └─Sigmoid: 4-4                 --                        --\n",
       "│    │    └─SpatialAttention: 3-4             --                        False\n",
       "│    │    │    └─Conv2d: 4-5                  (98)                      False\n",
       "│    │    │    └─Sigmoid: 4-6                 --                        --\n",
       "├─BottleneckWithCBAM: 1-2                     --                        False\n",
       "│    └─Conv2d: 2-10                           (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-11                      (128)                     False\n",
       "│    └─Conv2d: 2-12                           (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-13                      (128)                     False\n",
       "│    └─Conv2d: 2-14                           (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-15                      (512)                     False\n",
       "│    └─ReLU: 2-16                             --                        --\n",
       "│    └─CBAM: 2-17                             --                        False\n",
       "│    │    └─ChannelAttention: 3-5             --                        False\n",
       "│    │    │    └─AdaptiveAvgPool2d: 4-7       --                        --\n",
       "│    │    │    └─AdaptiveMaxPool2d: 4-8       --                        --\n",
       "│    │    │    └─Sequential: 4-9              --                        False\n",
       "│    │    │    │    └─Conv2d: 5-4             (4,096)                   False\n",
       "│    │    │    │    └─ReLU: 5-5               --                        --\n",
       "│    │    │    │    └─Conv2d: 5-6             (4,096)                   False\n",
       "│    │    │    └─Sigmoid: 4-10                --                        --\n",
       "│    │    └─SpatialAttention: 3-6             --                        False\n",
       "│    │    │    └─Conv2d: 4-11                 (98)                      False\n",
       "│    │    │    └─Sigmoid: 4-12                --                        --\n",
       "├─BottleneckWithCBAM: 1-3                     --                        False\n",
       "│    └─Conv2d: 2-18                           (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-19                      (128)                     False\n",
       "│    └─Conv2d: 2-20                           (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-21                      (128)                     False\n",
       "│    └─Conv2d: 2-22                           (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-23                      (512)                     False\n",
       "│    └─ReLU: 2-24                             --                        --\n",
       "│    └─CBAM: 2-25                             --                        False\n",
       "│    │    └─ChannelAttention: 3-7             --                        False\n",
       "│    │    │    └─AdaptiveAvgPool2d: 4-13      --                        --\n",
       "│    │    │    └─AdaptiveMaxPool2d: 4-14      --                        --\n",
       "│    │    │    └─Sequential: 4-15             --                        False\n",
       "│    │    │    │    └─Conv2d: 5-7             (4,096)                   False\n",
       "│    │    │    │    └─ReLU: 5-8               --                        --\n",
       "│    │    │    │    └─Conv2d: 5-9             (4,096)                   False\n",
       "│    │    │    └─Sigmoid: 4-16                --                        --\n",
       "│    │    └─SpatialAttention: 3-8             --                        False\n",
       "│    │    │    └─Conv2d: 4-17                 (98)                      False\n",
       "│    │    │    └─Sigmoid: 4-18                --                        --\n",
       "===============================================================================================\n",
       "Total params: 240,678\n",
       "Trainable params: 0\n",
       "Non-trainable params: 240,678\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.layer1, col_names=[\"num_params\", \"trainable\"], depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Param #                   Trainable\n",
       "==========================================================================================\n",
       "Sequential                               --                        False\n",
       "├─Bottleneck: 1-1                        --                        False\n",
       "│    └─Conv2d: 2-1                       (4,096)                   False\n",
       "│    └─BatchNorm2d: 2-2                  (128)                     False\n",
       "│    └─Conv2d: 2-3                       (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-4                  (128)                     False\n",
       "│    └─Conv2d: 2-5                       (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-6                  (512)                     False\n",
       "│    └─ReLU: 2-7                         --                        --\n",
       "│    └─Sequential: 2-8                   --                        False\n",
       "│    │    └─Conv2d: 3-1                  (16,384)                  False\n",
       "│    │    └─BatchNorm2d: 3-2             (512)                     False\n",
       "├─Bottleneck: 1-2                        --                        False\n",
       "│    └─Conv2d: 2-9                       (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-10                 (128)                     False\n",
       "│    └─Conv2d: 2-11                      (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-12                 (128)                     False\n",
       "│    └─Conv2d: 2-13                      (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-14                 (512)                     False\n",
       "│    └─ReLU: 2-15                        --                        --\n",
       "├─Bottleneck: 1-3                        --                        False\n",
       "│    └─Conv2d: 2-16                      (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-17                 (128)                     False\n",
       "│    └─Conv2d: 2-18                      (36,864)                  False\n",
       "│    └─BatchNorm2d: 2-19                 (128)                     False\n",
       "│    └─Conv2d: 2-20                      (16,384)                  False\n",
       "│    └─BatchNorm2d: 2-21                 (512)                     False\n",
       "│    └─ReLU: 2-22                        --                        --\n",
       "==========================================================================================\n",
       "Total params: 215,808\n",
       "Trainable params: 0\n",
       "Non-trainable params: 215,808\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "summary(model_orinin.layer1, col_names=[\"num_params\", \"trainable\"], depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khoi tao model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel_Attention(nn.Module):\n",
    "    '''Channel Attention in CBAM.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        '''Param init and architecture building.\n",
    "        '''\n",
    "\n",
    "        super(Channel_Attention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=channel_in, out_features=channel_in//reduction_ratio),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=channel_in//reduction_ratio, out_features=channel_in)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "\n",
    "        channel_attentions = []\n",
    "\n",
    "        for pool_types in self.pool_types:\n",
    "            if pool_types == 'avg':\n",
    "                pool_init = nn.AvgPool2d(kernel_size=(x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                avg_pool = pool_init(x)\n",
    "                channel_attentions.append(self.shared_mlp(avg_pool))\n",
    "            elif pool_types == 'max':\n",
    "                pool_init = nn.MaxPool2d(kernel_size=(x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                max_pool = pool_init(x)\n",
    "                channel_attentions.append(self.shared_mlp(max_pool))\n",
    "\n",
    "        pooling_sums = torch.stack(channel_attentions, dim=0).sum(dim=0)\n",
    "        scaled = nn.Sigmoid()(pooling_sums).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "\n",
    "        return x * scaled #return the element-wise multiplication between the input and the result.\n",
    "\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    '''Merge all the channels in a feature map into two separate channels where the first channel is produced by taking the max values from all channels, while the\n",
    "       second one is produced by taking the mean from every channel.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n",
    "\n",
    "\n",
    "class Spatial_Attention(nn.Module):\n",
    "    '''Spatial Attention in CBAM.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        '''Spatial Attention Architecture.\n",
    "        '''\n",
    "\n",
    "        super(Spatial_Attention, self).__init__()\n",
    "\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=1, kernel_size=kernel_size, stride=1, dilation=1, padding=(kernel_size-1)//2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1, eps=1e-5, momentum=0.01, affine=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "        x_compress = self.compress(x)\n",
    "        x_output = self.spatial_attention(x_compress)\n",
    "        scaled = nn.Sigmoid()(x_output)\n",
    "        return x * scaled\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    '''CBAM architecture.\n",
    "    '''\n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max'], spatial=True):\n",
    "        '''Param init and arch build.\n",
    "        '''\n",
    "        super(CBAM, self).__init__()\n",
    "        self.spatial = spatial\n",
    "\n",
    "        self.channel_attention = Channel_Attention(channel_in=channel_in, reduction_ratio=reduction_ratio, pool_types=pool_types)\n",
    "\n",
    "        if self.spatial:\n",
    "            self.spatial_attention = Spatial_Attention(kernel_size=7)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "        x_out = self.channel_attention(x)\n",
    "        if self.spatial:\n",
    "            x_out = self.spatial_attention(x_out)\n",
    "\n",
    "        return x_out\n",
    "    \n",
    "'''\n",
    "ResNet-50 Architecture.\n",
    "'''\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    '''Bottleneck modules\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, expansion=4, stride=1, use_cbam=True):\n",
    "        '''Param init.\n",
    "        '''\n",
    "        super(BottleNeck, self).__init__()\n",
    "\n",
    "        self.use_cbam = use_cbam\n",
    "        #only the first conv will be affected by the given stride parameter. The rest have default stride value (which is 1).\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels*expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channels*expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        #since the input has to be same size with the output during the identity mapping, whenever the stride or the number of output channels are\n",
    "        #more than 1 and expansion*out_channels respectively, the input, x, has to be downsampled to the same level as well.\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != expansion*out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=expansion*out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=out_channels*expansion)\n",
    "            )\n",
    "\n",
    "        if self.use_cbam:\n",
    "            self.cbam = CBAM(channel_in=out_channels*expansion)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.use_cbam:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += self.downsample(x) #identity connection/skip connection\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    '''ResNet-50 Architecture.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, use_cbam=True, image_depth=3, num_classes=6):\n",
    "        '''Params init and build arch.\n",
    "        '''\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.expansion = 4\n",
    "        self.num_blocks = [3, 3, 3, 2]\n",
    "\n",
    "        self.conv1  = nn.Conv2d(kernel_size=7, stride=2, in_channels=image_depth, out_channels=self.in_channels, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # self.conv_block1 = nn.Sequential(nn.Conv2d(kernel_size=7, stride=2, in_channels=image_depth, out_channels=self.in_channels, padding=3, bias=False),\n",
    "        #                                     nn.BatchNorm2d(self.in_channels),\n",
    "        #                                     nn.ReLU(inplace=True),\n",
    "        #                                     nn.MaxPool2d(stride=2, kernel_size=3, padding=1))\n",
    "\n",
    "        self.layer1 = self.make_layer(out_channels=64, num_blocks=self.num_blocks[0], stride=1, use_cbam=use_cbam)\n",
    "        self.layer2 = self.make_layer(out_channels=128, num_blocks=self.num_blocks[1], stride=2, use_cbam=use_cbam)\n",
    "        self.layer3 = self.make_layer(out_channels=256, num_blocks=self.num_blocks[2], stride=2, use_cbam=use_cbam)\n",
    "        self.layer4 = self.make_layer(out_channels=512, num_blocks=self.num_blocks[3], stride=2, use_cbam=use_cbam)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        # self.linear = nn.Linear(512*self.expansion, num_classes)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2048,1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024,512),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(in_features=512,\n",
    "                            out_features=2,\n",
    "                            bias=True)\n",
    "            )\n",
    "\n",
    "    def make_layer(self, out_channels, num_blocks, stride, use_cbam):\n",
    "        '''To construct the bottleneck layers.\n",
    "        '''\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BottleNeck(in_channels=self.in_channels, out_channels=out_channels, stride=stride, expansion=self.expansion, use_cbam=use_cbam))\n",
    "            self.in_channels = out_channels * self.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward propagation of ResNet-50.\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x_conv = self.layer4(x)\n",
    "        x = self.avgpool(x_conv)\n",
    "        x = nn.Flatten()(x) #flatten the feature maps.\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x_conv, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = trainable_extractor\n",
    "\n",
    "model = ResNet50(use_cbam=True, image_depth=3, num_classes=2)\n",
    "# Thay thế lớp fully connected\n",
    "# Chuyển toàn bộ model lên device sau khi đã thực hiện các thay đổi\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dungnd/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dungnd/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.0.cbam.channel_attention.shared_mlp.1.weight', 'layer1.0.cbam.channel_attention.shared_mlp.1.bias', 'layer1.0.cbam.channel_attention.shared_mlp.3.weight', 'layer1.0.cbam.channel_attention.shared_mlp.3.bias', 'layer1.0.cbam.spatial_attention.spatial_attention.0.weight', 'layer1.0.cbam.spatial_attention.spatial_attention.1.weight', 'layer1.0.cbam.spatial_attention.spatial_attention.1.bias', 'layer1.0.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer1.0.cbam.spatial_attention.spatial_attention.1.running_var', 'layer1.0.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.1.cbam.channel_attention.shared_mlp.1.weight', 'layer1.1.cbam.channel_attention.shared_mlp.1.bias', 'layer1.1.cbam.channel_attention.shared_mlp.3.weight', 'layer1.1.cbam.channel_attention.shared_mlp.3.bias', 'layer1.1.cbam.spatial_attention.spatial_attention.0.weight', 'layer1.1.cbam.spatial_attention.spatial_attention.1.weight', 'layer1.1.cbam.spatial_attention.spatial_attention.1.bias', 'layer1.1.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer1.1.cbam.spatial_attention.spatial_attention.1.running_var', 'layer1.1.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer1.2.cbam.channel_attention.shared_mlp.1.weight', 'layer1.2.cbam.channel_attention.shared_mlp.1.bias', 'layer1.2.cbam.channel_attention.shared_mlp.3.weight', 'layer1.2.cbam.channel_attention.shared_mlp.3.bias', 'layer1.2.cbam.spatial_attention.spatial_attention.0.weight', 'layer1.2.cbam.spatial_attention.spatial_attention.1.weight', 'layer1.2.cbam.spatial_attention.spatial_attention.1.bias', 'layer1.2.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer1.2.cbam.spatial_attention.spatial_attention.1.running_var', 'layer1.2.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.0.cbam.channel_attention.shared_mlp.1.weight', 'layer2.0.cbam.channel_attention.shared_mlp.1.bias', 'layer2.0.cbam.channel_attention.shared_mlp.3.weight', 'layer2.0.cbam.channel_attention.shared_mlp.3.bias', 'layer2.0.cbam.spatial_attention.spatial_attention.0.weight', 'layer2.0.cbam.spatial_attention.spatial_attention.1.weight', 'layer2.0.cbam.spatial_attention.spatial_attention.1.bias', 'layer2.0.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer2.0.cbam.spatial_attention.spatial_attention.1.running_var', 'layer2.0.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.1.cbam.channel_attention.shared_mlp.1.weight', 'layer2.1.cbam.channel_attention.shared_mlp.1.bias', 'layer2.1.cbam.channel_attention.shared_mlp.3.weight', 'layer2.1.cbam.channel_attention.shared_mlp.3.bias', 'layer2.1.cbam.spatial_attention.spatial_attention.0.weight', 'layer2.1.cbam.spatial_attention.spatial_attention.1.weight', 'layer2.1.cbam.spatial_attention.spatial_attention.1.bias', 'layer2.1.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer2.1.cbam.spatial_attention.spatial_attention.1.running_var', 'layer2.1.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.2.cbam.channel_attention.shared_mlp.1.weight', 'layer2.2.cbam.channel_attention.shared_mlp.1.bias', 'layer2.2.cbam.channel_attention.shared_mlp.3.weight', 'layer2.2.cbam.channel_attention.shared_mlp.3.bias', 'layer2.2.cbam.spatial_attention.spatial_attention.0.weight', 'layer2.2.cbam.spatial_attention.spatial_attention.1.weight', 'layer2.2.cbam.spatial_attention.spatial_attention.1.bias', 'layer2.2.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer2.2.cbam.spatial_attention.spatial_attention.1.running_var', 'layer2.2.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.0.cbam.channel_attention.shared_mlp.1.weight', 'layer3.0.cbam.channel_attention.shared_mlp.1.bias', 'layer3.0.cbam.channel_attention.shared_mlp.3.weight', 'layer3.0.cbam.channel_attention.shared_mlp.3.bias', 'layer3.0.cbam.spatial_attention.spatial_attention.0.weight', 'layer3.0.cbam.spatial_attention.spatial_attention.1.weight', 'layer3.0.cbam.spatial_attention.spatial_attention.1.bias', 'layer3.0.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer3.0.cbam.spatial_attention.spatial_attention.1.running_var', 'layer3.0.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.1.cbam.channel_attention.shared_mlp.1.weight', 'layer3.1.cbam.channel_attention.shared_mlp.1.bias', 'layer3.1.cbam.channel_attention.shared_mlp.3.weight', 'layer3.1.cbam.channel_attention.shared_mlp.3.bias', 'layer3.1.cbam.spatial_attention.spatial_attention.0.weight', 'layer3.1.cbam.spatial_attention.spatial_attention.1.weight', 'layer3.1.cbam.spatial_attention.spatial_attention.1.bias', 'layer3.1.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer3.1.cbam.spatial_attention.spatial_attention.1.running_var', 'layer3.1.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.2.cbam.channel_attention.shared_mlp.1.weight', 'layer3.2.cbam.channel_attention.shared_mlp.1.bias', 'layer3.2.cbam.channel_attention.shared_mlp.3.weight', 'layer3.2.cbam.channel_attention.shared_mlp.3.bias', 'layer3.2.cbam.spatial_attention.spatial_attention.0.weight', 'layer3.2.cbam.spatial_attention.spatial_attention.1.weight', 'layer3.2.cbam.spatial_attention.spatial_attention.1.bias', 'layer3.2.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer3.2.cbam.spatial_attention.spatial_attention.1.running_var', 'layer3.2.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.0.cbam.channel_attention.shared_mlp.1.weight', 'layer4.0.cbam.channel_attention.shared_mlp.1.bias', 'layer4.0.cbam.channel_attention.shared_mlp.3.weight', 'layer4.0.cbam.channel_attention.shared_mlp.3.bias', 'layer4.0.cbam.spatial_attention.spatial_attention.0.weight', 'layer4.0.cbam.spatial_attention.spatial_attention.1.weight', 'layer4.0.cbam.spatial_attention.spatial_attention.1.bias', 'layer4.0.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer4.0.cbam.spatial_attention.spatial_attention.1.running_var', 'layer4.0.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.1.cbam.channel_attention.shared_mlp.1.weight', 'layer4.1.cbam.channel_attention.shared_mlp.1.bias', 'layer4.1.cbam.channel_attention.shared_mlp.3.weight', 'layer4.1.cbam.channel_attention.shared_mlp.3.bias', 'layer4.1.cbam.spatial_attention.spatial_attention.0.weight', 'layer4.1.cbam.spatial_attention.spatial_attention.1.weight', 'layer4.1.cbam.spatial_attention.spatial_attention.1.bias', 'layer4.1.cbam.spatial_attention.spatial_attention.1.running_mean', 'layer4.1.cbam.spatial_attention.spatial_attention.1.running_var', 'layer4.1.cbam.spatial_attention.spatial_attention.1.num_batches_tracked', 'linear.0.weight', 'linear.0.bias', 'linear.2.weight', 'linear.2.bias', 'linear.4.weight', 'linear.4.bias'])\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Tải mô hình ResNet50 đã được huấn luyện trước từ torchvision\n",
    "pretrained_model = models.resnet50(pretrained=True)\n",
    "pretrained_dict = pretrained_model.state_dict()\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Lọc các keys không khớp giữa pretrained_dict và model_dict\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "print(pretrained_dict.keys())\n",
    "print(model_dict.keys())\n",
    "print(pretrained_dict.keys())\n",
    "# Cập nhật model_dict với các weights từ pretrained_dict\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load state dict vào model\n",
    "model.load_state_dict(model_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape               Output Shape              Param #                   Trainable\n",
       "================================================================================================================================================================\n",
       "ResNet50 (ResNet50)                                          [16, 3, 224, 224]         [16, 2048, 7, 7]          --                        True\n",
       "├─Conv2d (conv1)                                             [16, 3, 224, 224]         [16, 64, 112, 112]        9,408                     True\n",
       "├─BatchNorm2d (bn1)                                          [16, 64, 112, 112]        [16, 64, 112, 112]        128                       True\n",
       "├─ReLU (relu)                                                [16, 64, 112, 112]        [16, 64, 112, 112]        --                        --\n",
       "├─MaxPool2d (maxpool)                                        [16, 64, 112, 112]        [16, 64, 56, 56]          --                        --\n",
       "├─Sequential (layer1)                                        [16, 64, 56, 56]          [16, 256, 56, 56]         --                        True\n",
       "│    └─BottleNeck (0)                                        [16, 64, 56, 56]          [16, 256, 56, 56]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          4,096                     True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          36,864                    True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         16,384                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         512                       True\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  4,112                     True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 4,352                     True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 256, 56, 56]         [16, 2, 56, 56]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 56, 56]           [16, 1, 56, 56]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 56, 56]           [16, 1, 56, 56]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 56, 56]           [16, 1, 56, 56]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 64, 56, 56]          [16, 256, 56, 56]         --                        True\n",
       "│    │    │    └─Conv2d (0)                                  [16, 64, 56, 56]          [16, 256, 56, 56]         16,384                    True\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 256, 56, 56]         [16, 256, 56, 56]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --\n",
       "│    └─BottleNeck (1)                                        [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 64, 56, 56]          16,384                    True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          36,864                    True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         16,384                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         512                       True\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  4,112                     True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 4,352                     True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 256, 56, 56]         [16, 2, 56, 56]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 56, 56]           [16, 1, 56, 56]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 56, 56]           [16, 1, 56, 56]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 56, 56]           [16, 1, 56, 56]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --\n",
       "│    └─BottleNeck (2)                                        [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 64, 56, 56]          16,384                    True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 64, 56, 56]          [16, 64, 56, 56]          36,864                    True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 64, 56, 56]          [16, 64, 56, 56]          128                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 64, 56, 56]          [16, 64, 56, 56]          --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 64, 56, 56]          [16, 256, 56, 56]         16,384                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 256, 56, 56]         [16, 256, 56, 56]         512                       True\n",
       "│    │    └─CBAM (cbam)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  4,112                     True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 4,352                     True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 256, 1, 1]           [16, 256]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 256, 1, 1]           [16, 256]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 256]                 [16, 16]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 16]                  [16, 16]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 16]                  [16, 256]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 256, 56, 56]         [16, 256, 56, 56]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 256, 56, 56]         [16, 2, 56, 56]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 56, 56]           [16, 1, 56, 56]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 56, 56]           [16, 1, 56, 56]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 56, 56]           [16, 1, 56, 56]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 56, 56]         [16, 256, 56, 56]         --                        --\n",
       "├─Sequential (layer2)                                        [16, 256, 56, 56]         [16, 512, 28, 28]         --                        True\n",
       "│    └─BottleNeck (0)                                        [16, 256, 56, 56]         [16, 512, 28, 28]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 256, 56, 56]         [16, 128, 28, 28]         32,768                    True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         147,456                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         65,536                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         1,024                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  16,416                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 16,896                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 512, 28, 28]         [16, 2, 28, 28]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 28, 28]           [16, 1, 28, 28]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 28, 28]           [16, 1, 28, 28]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 28, 28]           [16, 1, 28, 28]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 256, 56, 56]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    └─Conv2d (0)                                  [16, 256, 56, 56]         [16, 512, 28, 28]         131,072                   True\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 512, 28, 28]         [16, 512, 28, 28]         1,024                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --\n",
       "│    └─BottleNeck (1)                                        [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 128, 28, 28]         65,536                    True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         147,456                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         65,536                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         1,024                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  16,416                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 16,896                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 512, 28, 28]         [16, 2, 28, 28]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 28, 28]           [16, 1, 28, 28]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 28, 28]           [16, 1, 28, 28]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 28, 28]           [16, 1, 28, 28]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --\n",
       "│    └─BottleNeck (2)                                        [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 128, 28, 28]         65,536                    True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 128, 28, 28]         [16, 128, 28, 28]         147,456                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 128, 28, 28]         [16, 128, 28, 28]         256                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 128, 28, 28]         [16, 128, 28, 28]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 128, 28, 28]         [16, 512, 28, 28]         65,536                    True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 512, 28, 28]         [16, 512, 28, 28]         1,024                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  16,416                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 16,896                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 512, 1, 1]           [16, 512]                 (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 512, 1, 1]           [16, 512]                 --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 512]                 [16, 32]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 32]                  [16, 32]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 32]                  [16, 512]                 (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 512, 28, 28]         [16, 512, 28, 28]         --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 512, 28, 28]         [16, 2, 28, 28]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 28, 28]           [16, 1, 28, 28]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 28, 28]           [16, 1, 28, 28]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 28, 28]           [16, 1, 28, 28]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 28, 28]         [16, 512, 28, 28]         --                        --\n",
       "├─Sequential (layer3)                                        [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        True\n",
       "│    └─BottleNeck (0)                                        [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 512, 28, 28]         [16, 256, 14, 14]         131,072                   True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         589,824                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        262,144                   True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        2,048                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  65,600                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                66,560                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 1024, 14, 14]        [16, 2, 14, 14]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 14, 14]           [16, 1, 14, 14]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 14, 14]           [16, 1, 14, 14]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 14, 14]           [16, 1, 14, 14]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 512, 28, 28]         [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    └─Conv2d (0)                                  [16, 512, 28, 28]         [16, 1024, 14, 14]        524,288                   True\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 1024, 14, 14]        [16, 1024, 14, 14]        2,048                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --\n",
       "│    └─BottleNeck (1)                                        [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         262,144                   True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         589,824                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        262,144                   True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        2,048                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  65,600                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                66,560                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 1024, 14, 14]        [16, 2, 14, 14]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 14, 14]           [16, 1, 14, 14]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 14, 14]           [16, 1, 14, 14]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 14, 14]           [16, 1, 14, 14]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --\n",
       "│    └─BottleNeck (2)                                        [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 256, 14, 14]         262,144                   True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 256, 14, 14]         [16, 256, 14, 14]         589,824                   True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 256, 14, 14]         [16, 256, 14, 14]         512                       True\n",
       "│    │    └─ReLU (relu)                                      [16, 256, 14, 14]         [16, 256, 14, 14]         --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 256, 14, 14]         [16, 1024, 14, 14]        262,144                   True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 1024, 14, 14]        [16, 1024, 14, 14]        2,048                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  65,600                    True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                66,560                    True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 1024, 1, 1]          [16, 1024]                (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 1024, 1, 1]          [16, 1024]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 1024]                [16, 64]                  (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 64]                  [16, 64]                  --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 64]                  [16, 1024]                (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 1024, 14, 14]        [16, 2, 14, 14]           --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 14, 14]           [16, 1, 14, 14]           --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 14, 14]           [16, 1, 14, 14]           98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 14, 14]           [16, 1, 14, 14]           2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 1024, 14, 14]        [16, 1024, 14, 14]        --                        --\n",
       "├─Sequential (layer4)                                        [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        True\n",
       "│    └─BottleNeck (0)                                        [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 1024, 14, 14]        [16, 512, 7, 7]           524,288                   True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 512, 7, 7]           [16, 512, 7, 7]           1,024                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 512, 7, 7]           [16, 512, 7, 7]           2,359,296                 True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 512, 7, 7]           [16, 512, 7, 7]           1,024                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 512, 7, 7]           [16, 2048, 7, 7]          1,048,576                 True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          4,096                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 2048, 1, 1]          [16, 2048]                --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 2048, 1, 1]          [16, 2048]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 2048]                [16, 128]                 262,272                   True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 128]                 [16, 128]                 --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 128]                 [16, 2048]                264,192                   True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 2048, 1, 1]          [16, 2048]                (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 2048, 1, 1]          [16, 2048]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 2048]                [16, 128]                 (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 128]                 [16, 128]                 --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 128]                 [16, 2048]                (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 2048, 7, 7]          [16, 2, 7, 7]             --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 7, 7]             [16, 1, 7, 7]             --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 7, 7]             [16, 1, 7, 7]             98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 7, 7]             [16, 1, 7, 7]             2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 1024, 14, 14]        [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    └─Conv2d (0)                                  [16, 1024, 14, 14]        [16, 2048, 7, 7]          2,097,152                 True\n",
       "│    │    │    └─BatchNorm2d (1)                             [16, 2048, 7, 7]          [16, 2048, 7, 7]          4,096                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --\n",
       "│    └─BottleNeck (1)                                        [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    └─Conv2d (conv1)                                   [16, 2048, 7, 7]          [16, 512, 7, 7]           1,048,576                 True\n",
       "│    │    └─BatchNorm2d (bn1)                                [16, 512, 7, 7]           [16, 512, 7, 7]           1,024                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --\n",
       "│    │    └─Conv2d (conv2)                                   [16, 512, 7, 7]           [16, 512, 7, 7]           2,359,296                 True\n",
       "│    │    └─BatchNorm2d (bn2)                                [16, 512, 7, 7]           [16, 512, 7, 7]           1,024                     True\n",
       "│    │    └─ReLU (relu)                                      [16, 512, 7, 7]           [16, 512, 7, 7]           --                        --\n",
       "│    │    └─Conv2d (conv3)                                   [16, 512, 7, 7]           [16, 2048, 7, 7]          1,048,576                 True\n",
       "│    │    └─BatchNorm2d (bn3)                                [16, 2048, 7, 7]          [16, 2048, 7, 7]          4,096                     True\n",
       "│    │    └─CBAM (cbam)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    └─Channel_Attention (channel_attention)       [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 2048, 1, 1]          [16, 2048]                --                        True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 2048, 1, 1]          [16, 2048]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 2048]                [16, 128]                 262,272                   True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 128]                 [16, 128]                 --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 128]                 [16, 2048]                264,192                   True\n",
       "│    │    │    │    └─Sequential (shared_mlp)                [16, 2048, 1, 1]          [16, 2048]                (recursive)               True\n",
       "│    │    │    │    │    └─Flatten (0)                       [16, 2048, 1, 1]          [16, 2048]                --                        --\n",
       "│    │    │    │    │    └─Linear (1)                        [16, 2048]                [16, 128]                 (recursive)               True\n",
       "│    │    │    │    │    └─ReLU (2)                          [16, 128]                 [16, 128]                 --                        --\n",
       "│    │    │    │    │    └─Linear (3)                        [16, 128]                 [16, 2048]                (recursive)               True\n",
       "│    │    │    └─Spatial_Attention (spatial_attention)       [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        True\n",
       "│    │    │    │    └─ChannelPool (compress)                 [16, 2048, 7, 7]          [16, 2, 7, 7]             --                        --\n",
       "│    │    │    │    └─Sequential (spatial_attention)         [16, 2, 7, 7]             [16, 1, 7, 7]             --                        True\n",
       "│    │    │    │    │    └─Conv2d (0)                        [16, 2, 7, 7]             [16, 1, 7, 7]             98                        True\n",
       "│    │    │    │    │    └─BatchNorm2d (1)                   [16, 1, 7, 7]             [16, 1, 7, 7]             2                         True\n",
       "│    │    └─Sequential (downsample)                          [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --\n",
       "│    │    └─ReLU (relu)                                      [16, 2048, 7, 7]          [16, 2048, 7, 7]          --                        --\n",
       "├─AvgPool2d (avgpool)                                        [16, 2048, 7, 7]          [16, 2048, 1, 1]          --                        --\n",
       "├─Sequential (linear)                                        [16, 2048]                [16, 2]                   --                        True\n",
       "│    └─Linear (0)                                            [16, 2048]                [16, 1024]                2,098,176                 True\n",
       "│    └─ReLU (1)                                              [16, 1024]                [16, 1024]                --                        --\n",
       "│    └─Linear (2)                                            [16, 1024]                [16, 512]                 524,800                   True\n",
       "│    └─Dropout (3)                                           [16, 512]                 [16, 512]                 --                        --\n",
       "│    └─Linear (4)                                            [16, 512]                 [16, 2]                   1,026                     True\n",
       "================================================================================================================================================================\n",
       "Total params: 19,613,662\n",
       "Trainable params: 19,613,662\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 44.34\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2292.38\n",
       "Params size (MB): 78.45\n",
       "Estimated Total Size (MB): 2380.47\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(16, 3, 224, 224), row_settings=[\"var_names\"],col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], depth=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 2/22052 [00:30<93:42:48, 15.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 164\u001b[0m\n\u001b[1;32m    161\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m    162\u001b[0m train_dataloader, test_dataloader \u001b[38;5;241m=\u001b[39m load_data(train_dir, valid_dir, batch_size)\n\u001b[0;32m--> 164\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResNet50_CBAM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 100\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, checkpoint_model_name, epochs, pretrained)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, start_epoch \u001b[38;5;241m+\u001b[39m epochs):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m,epoch)\n\u001b[0;32m--> 100\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    105\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    106\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# 4. Print out what's happening\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m, in \u001b[0;36mBottleneckWithCBAM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     59\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for (X, y) in tqdm(dataloader, desc=\"Batch\"):\n",
    "        # Send data to target device\n",
    "        # print(\"\\rbatch: \" + str(batch) + \"/\" + str(round(int(100000/64))), end = \"\")\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          checkpoint_model_name: str = \"\",\n",
    "          epochs: int = 5,\n",
    "          pretrained: str = None):\n",
    "    # 1. Take in various parameters required for training and test steps\n",
    "\n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    if pretrained:\n",
    "        model_state_dict, optimizer_state_dict, start_epoch = load_checkpoint(pretrained)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        optimizer.load_state_dict(optimizer_state_dict)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in range(start_epoch+1, start_epoch + epochs):\n",
    "        print(\"Epoch:\",epoch)\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        # 6. Save Checkpoints\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc\n",
    "        }\n",
    "        torch.save(checkpoint, f\"checkpoints/{checkpoint_model_name}_epoch_{epoch:02d}.pth\")\n",
    "        \n",
    "    # 7. Return the filled results at the end of the epochs\n",
    "    return results\n",
    "\n",
    "def load_data(train_dir: str, valid_dir: str, batch_size: int = 32):\n",
    "    # Define transforms\n",
    "    weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "    auto_transforms = weights.transforms()\n",
    "\n",
    "    # Load data\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=auto_transforms, target_transform = None)\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=auto_transforms)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device= \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "train_dir=\"archive/dataset/train\"\n",
    "valid_dir=\"archive/dataset/valid\"\n",
    "test_dir=\"archive/dataset/test\"\n",
    "\n",
    "model = init_model_ResNet50_CBAM()\n",
    "# Train\n",
    "batch_size = 16\n",
    "train_dataloader, test_dataloader = load_data(train_dir, valid_dir, batch_size)\n",
    "\n",
    "train(model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "        checkpoint_model_name=\"ResNet50_CBAM\",\n",
    "        epochs=10,\n",
    "        pretrained=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
