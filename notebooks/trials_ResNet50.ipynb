{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Fuzzy Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dungnd/Documents/AI/fake-faces-detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dir: str, valid_dir: str, batch_size: int = 64):\n",
    "    # Define transforms\n",
    "    weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "    auto_transforms = weights.transforms()\n",
    "\n",
    "    # Load data\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=auto_transforms, target_transform = None)\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=auto_transforms)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"archive/dataset/train\"\n",
    "valid_dir=\"archive/dataset/valid\"\n",
    "test_dir=\"archive/dataset/test\"\n",
    "\n",
    "train_loader, valid_loader = load_data(train_dir, valid_dir, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 384, 384])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m membership, centroids\n\u001b[0;32m---> 47\u001b[0m membership1_target, centroids1 \u001b[38;5;241m=\u001b[39m fuzzy_c_means(\u001b[43mtrain_data\u001b[49m, num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, fuzziness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def fuzzy_c_means(train_loader, num_clusters, fuzziness=2, max_iter=100, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Thực hiện thuật toán Fuzzy C-Means.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Tensor dữ liệu đầu vào (mẫu x đặc trưng).\n",
    "        num_clusters (int): Số lượng cluster.\n",
    "        fuzziness (float): Tham số fuzziness (p trong bài báo).\n",
    "        max_iter (int): Số lượng vòng lặp tối đa.\n",
    "        tol (float): Ngưỡng dung sai để dừng thuật toán.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Ma trận độ thuộc (mẫu x cluster).\n",
    "        torch.Tensor: Ma trận centroids (cluster x đặc trưng).\n",
    "    \"\"\"\n",
    "    num_samples, num_features = train_loader.shape\n",
    "\n",
    "    # Khởi tạo centroids ngẫu nhiên\n",
    "    centroids = torch.randn(num_clusters, num_features)\n",
    "    for X, y in train_loader:\n",
    "        for iteration in range(max_iter):\n",
    "            old_centroids = centroids.clone()\n",
    "\n",
    "            # Tính toán ma trận khoảng cách (Euclidean)\n",
    "            distances = torch.cdist(data, centroids)\n",
    "\n",
    "            # Tính toán ma trận độ thuộc (Equation 3 trong bài báo)\n",
    "            membership = 1 / torch.pow(distances / (distances.sum(dim=1, keepdim=True) + 1e-9), 2 / (fuzziness - 1))\n",
    "            membership = membership / (membership.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "            # Cập nhật centroids (Equation 2 trong bài báo)\n",
    "            numerator = torch.matmul(membership.pow(fuzziness).T, data)\n",
    "            denominator = membership.pow(fuzziness).sum(dim=0, keepdim=True).T\n",
    "            centroids = numerator / (denominator + 1e-9)\n",
    "\n",
    "            # Kiểm tra điều kiện dừng\n",
    "            if torch.all(torch.abs(centroids - old_centroids) < tol):\n",
    "                break\n",
    "\n",
    "    return membership, centroids\n",
    "\n",
    "membership1_target, centroids1 = fuzzy_c_means(train_data, num_clusters = 2, fuzziness=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dungnd/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dungnd/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class FuzzyClusteringLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_clusters):\n",
    "        super(FuzzyClusteringLayer, self).__init__()\n",
    "        self.num_clusters = num_clusters\n",
    "        self.centroids = nn.Parameter(torch.randn(num_clusters, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tính khoảng cách Euclidean giữa các điểm dữ liệu và các centroid\n",
    "        distances = torch.cdist(x, self.centroids)\n",
    "        # Tính toán độ thuộc (membership degrees) bằng cách sử dụng hàm mũ hóa (có thể điều chỉnh tham số fuzziness)\n",
    "        fuzziness = 2\n",
    "        membership = torch.pow(1 / distances, 2 / (fuzziness - 1))\n",
    "        # Chuẩn hóa độ thuộc để tổng của mỗi điểm dữ liệu bằng 1\n",
    "        membership = membership / torch.sum(membership, dim=1, keepdim=True)\n",
    "        return membership, distances\n",
    "\n",
    "class Resnet50_FuzzyCluster(nn.Module):\n",
    "    def __init__(self, num_clusters_fc1=2, num_clusters_fc2=5):\n",
    "        super(Resnet50_FuzzyCluster, self).__init__()\n",
    "        # Tải pre-trained ResNet50\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        # Khối Sequential các lớp fully connected\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "        # Các lớp fuzzy clustering\n",
    "        self.fuzzy_cluster1 = FuzzyClusteringLayer(1024, num_clusters_fc1)\n",
    "        self.fuzzy_cluster2 = FuzzyClusteringLayer(512, num_clusters_fc2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass qua ResNet50\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass qua lớp FC đầu tiên\n",
    "        fc1_out = self.fc[0](x)\n",
    "        fc1_relu_out = self.fc[1](fc1_out)\n",
    "\n",
    "        # Fuzzy clustering sau lớp FC đầu tiên\n",
    "        membership1, distances1 = self.fuzzy_cluster1(fc1_relu_out)\n",
    "\n",
    "        # Forward pass qua lớp FC thứ hai\n",
    "        fc2_out = self.fc[2](fc1_relu_out)\n",
    "        fc2_relu_out = self.fc[3](fc2_out)\n",
    "\n",
    "        # Fuzzy clustering sau lớp FC thứ hai\n",
    "        membership2, distances2 = self.fuzzy_cluster2(fc2_relu_out)\n",
    "\n",
    "        # Forward pass qua lớp FC cuối cùng\n",
    "        output = self.fc[4](fc2_relu_out)\n",
    "\n",
    "        return output, membership1, distances1, membership2, distances2\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = Resnet50_FuzzyCluster(num_clusters_fc1=10, num_clusters_fc2=5)\n",
    "\n",
    "\n",
    "# Ví dụ về forward pass với một batch dữ liệu ngẫu nhiên\n",
    "# input_tensor \n",
    "# output, membership1, distances1, membership2, distances2 = model(input_tensor)\n",
    "\n",
    "# print(\"Kích thước output:\", output.shape)\n",
    "# print(\"Kích thước membership lớp 1:\", membership1.shape)\n",
    "# print(\"Kích thước khoảng cá= torch.randn(64, 3, 224, 224)ch lớp 1:\", distances1.shape)\n",
    "# print(\"Kích thước membership lớp 2:\", membership2.shape)\n",
    "# print(\"Kích thước khoảng cách lớp 2:\", distances2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "======================================================================================================================================================\n",
       "Resnet50_FuzzyCluster (Resnet50_FuzzyCluster)      [32, 3, 224, 224]         [32, 2]                   --                        --\n",
       "├─Sequential (resnet)                              [32, 3, 224, 224]         [32, 2048, 1, 1]          --                        --\n",
       "│    └─Conv2d (0)                                  [32, 3, 224, 224]         [32, 64, 112, 112]        9,408                     [7, 7]\n",
       "│    └─BatchNorm2d (1)                             [32, 64, 112, 112]        [32, 64, 112, 112]        128                       --\n",
       "│    └─ReLU (2)                                    [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n",
       "│    └─MaxPool2d (3)                               [32, 64, 112, 112]        [32, 64, 56, 56]          --                        3\n",
       "│    └─Sequential (4)                              [32, 64, 56, 56]          [32, 256, 56, 56]         --                        --\n",
       "│    │    └─Bottleneck (0)                         [32, 64, 56, 56]          [32, 256, 56, 56]         75,008                    --\n",
       "│    │    └─Bottleneck (1)                         [32, 256, 56, 56]         [32, 256, 56, 56]         70,400                    --\n",
       "│    │    └─Bottleneck (2)                         [32, 256, 56, 56]         [32, 256, 56, 56]         70,400                    --\n",
       "│    └─Sequential (5)                              [32, 256, 56, 56]         [32, 512, 28, 28]         --                        --\n",
       "│    │    └─Bottleneck (0)                         [32, 256, 56, 56]         [32, 512, 28, 28]         379,392                   --\n",
       "│    │    └─Bottleneck (1)                         [32, 512, 28, 28]         [32, 512, 28, 28]         280,064                   --\n",
       "│    │    └─Bottleneck (2)                         [32, 512, 28, 28]         [32, 512, 28, 28]         280,064                   --\n",
       "│    │    └─Bottleneck (3)                         [32, 512, 28, 28]         [32, 512, 28, 28]         280,064                   --\n",
       "│    └─Sequential (6)                              [32, 512, 28, 28]         [32, 1024, 14, 14]        --                        --\n",
       "│    │    └─Bottleneck (0)                         [32, 512, 28, 28]         [32, 1024, 14, 14]        1,512,448                 --\n",
       "│    │    └─Bottleneck (1)                         [32, 1024, 14, 14]        [32, 1024, 14, 14]        1,117,184                 --\n",
       "│    │    └─Bottleneck (2)                         [32, 1024, 14, 14]        [32, 1024, 14, 14]        1,117,184                 --\n",
       "│    │    └─Bottleneck (3)                         [32, 1024, 14, 14]        [32, 1024, 14, 14]        1,117,184                 --\n",
       "│    │    └─Bottleneck (4)                         [32, 1024, 14, 14]        [32, 1024, 14, 14]        1,117,184                 --\n",
       "│    │    └─Bottleneck (5)                         [32, 1024, 14, 14]        [32, 1024, 14, 14]        1,117,184                 --\n",
       "│    └─Sequential (7)                              [32, 1024, 14, 14]        [32, 2048, 7, 7]          --                        --\n",
       "│    │    └─Bottleneck (0)                         [32, 1024, 14, 14]        [32, 2048, 7, 7]          6,039,552                 --\n",
       "│    │    └─Bottleneck (1)                         [32, 2048, 7, 7]          [32, 2048, 7, 7]          4,462,592                 --\n",
       "│    │    └─Bottleneck (2)                         [32, 2048, 7, 7]          [32, 2048, 7, 7]          4,462,592                 --\n",
       "│    └─AdaptiveAvgPool2d (8)                       [32, 2048, 7, 7]          [32, 2048, 1, 1]          --                        --\n",
       "├─Sequential (fc)                                  --                        --                        (recursive)               --\n",
       "│    └─Linear (0)                                  [32, 2048]                [32, 1024]                2,098,176                 --\n",
       "│    └─ReLU (1)                                    [32, 1024]                [32, 1024]                --                        --\n",
       "├─FuzzyClusteringLayer (fuzzy_cluster1)            [32, 1024]                [32, 10]                  10,240                    --\n",
       "├─Sequential (fc)                                  --                        --                        (recursive)               --\n",
       "│    └─Linear (2)                                  [32, 1024]                [32, 512]                 524,800                   --\n",
       "│    └─ReLU (3)                                    [32, 512]                 [32, 512]                 --                        --\n",
       "├─FuzzyClusteringLayer (fuzzy_cluster2)            [32, 512]                 [32, 5]                   2,560                     --\n",
       "├─Sequential (fc)                                  --                        --                        (recursive)               --\n",
       "│    └─Linear (4)                                  [32, 512]                 [32, 2]                   1,026                     --\n",
       "======================================================================================================================================================\n",
       "Total params: 26,144,834\n",
       "Trainable params: 26,144,834\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 130.87\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5690.76\n",
       "Params size (MB): 104.58\n",
       "Estimated Total Size (MB): 5814.60\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = init_model_ResNet50(trainable_extractor = False)\n",
    "summary(model, (32, 3, 224, 224), device=device, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"], row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, classification_weight=0.9, clustering_weight=0.1, alpha1=0.5, alpha2=0.5):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.classification_loss_fn = nn.CrossEntropyLoss()\n",
    "        self.clustering_weight = clustering_weight\n",
    "        self.classification_weight = classification_weight\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "\n",
    "    def forward(self, output, target, membership1, distances1, membership2, distances2, fuzzy_cluster_results1=None, fuzzy_cluster_results2=None):\n",
    "        # Tính toán Classification Loss\n",
    "        classification_loss = self.classification_loss_fn(output, target)\n",
    "\n",
    "        # Tính toán Clustering Cost cho lớp thứ nhất\n",
    "        clustering_loss1 = torch.tensor(0.0, requires_grad=True).to(output.device)\n",
    "        if fuzzy_cluster_results1 is not None:\n",
    "            # Tính toán MSE giữa membership và fuzzy_cluster_results1\n",
    "            mse_loss1 = F.mse_loss(membership1, fuzzy_cluster_results1)\n",
    "            # Tính toán Binary Cross Entropy Loss với zero vector\n",
    "            batch_size = membership1.size(0)\n",
    "            num_clusters1 = membership1.size(1)\n",
    "            zero_target1 = torch.zeros(batch_size, num_clusters1).to(membership1.device)\n",
    "            bce_loss1 = F.binary_cross_entropy(membership1, zero_target1)\n",
    "            clustering_loss1 = mse_loss1 + bce_loss1\n",
    "\n",
    "        # Tính toán Clustering Cost cho lớp thứ hai\n",
    "        clustering_loss2 = torch.tensor(0.0, requires_grad=True).to(output.device)\n",
    "        if fuzzy_cluster_results2 is not None:\n",
    "            # Tính toán MSE giữa membership và fuzzy_cluster_results2\n",
    "            mse_loss2 = F.mse_loss(membership2, fuzzy_cluster_results2)\n",
    "            # Tính toán Binary Cross Entropy Loss với zero vector\n",
    "            batch_size = membership2.size(0)\n",
    "            num_clusters2 = membership2.size(1)\n",
    "            zero_target2 = torch.zeros(batch_size, num_clusters2).to(membership2.device)\n",
    "            bce_loss2 = F.binary_cross_entropy(membership2, zero_target2)\n",
    "            clustering_loss2 = mse_loss2 + bce_loss2\n",
    "\n",
    "        # Tổng hợp Clustering Cost\n",
    "        total_clustering_loss = self.alpha1 * clustering_loss1 + self.alpha2 * clustering_loss2\n",
    "\n",
    "        # Tổng hợp Total Cost\n",
    "        total_loss = self.classification_weight * classification_loss + self.clustering_weight * total_clustering_loss\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CustomLoss.forward() missing 6 required positional arguments: 'output', 'target', 'membership1', 'distances1', 'membership2', and 'distances2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m CustomLoss \u001b[38;5;241m=\u001b[39m \u001b[43mCustomLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m summary(CustomLoss)\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AI/fake-faces-detection/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: CustomLoss.forward() missing 6 required positional arguments: 'output', 'target', 'membership1', 'distances1', 'membership2', and 'distances2'"
     ]
    }
   ],
   "source": [
    "CustomLoss = CustomLoss()\n",
    "summary(CustomLoss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
